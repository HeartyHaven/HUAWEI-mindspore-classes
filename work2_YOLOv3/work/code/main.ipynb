{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 下面一段代码需要进行代码补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## train YOLOv3 example ########################\n",
    "import os\n",
    "import argparse\n",
    "import ast\n",
    "from easydict import EasyDict as edict\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下代码需补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入numpy，取名为np\n",
    "import numpy as np\n",
    "#导入MindSpore网络类算子(nn模块)，取名为nn\n",
    "import mindspore.nn as nn\n",
    "#导入MindSpore上下文设置context以及张量Tensor\n",
    "from mindspore import context, Tensor\n",
    "#导入MindSpore模型构建模块Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.communication.management import init\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, LossMonitor, TimeMonitor   \n",
    "from mindspore.train import Model             \n",
    "from mindspore.context import ParallelMode\n",
    "from src.yolov3 import yolov3_resnet18\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net  #查不到mindspore.train.serialization\n",
    "from mindspore.common.initializer import initializer\n",
    "from mindspore.common import set_seed         \n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'.src/yolov3/yolov3_resnet18/')      #yours code path\n",
    "#sys.path.insert(0,'./yolov3/code/')\n",
    "\n",
    "#从src工具文件夹中的yolov3.py文件中导入yolov3_resnet18模型\n",
    "\n",
    "from src.yolov3 import YoloWithLossCell, TrainingWrapper\n",
    "from src.dataset import create_yolo_dataset, data_to_mindrecord_byte_image\n",
    "from src.config import ConfigYOLOV3ResNet18\n",
    "\n",
    "set_seed(1)\n",
    "\n",
    "def get_lr(learning_rate, start_step, global_step, decay_step, decay_rate, steps=False):\n",
    "    \"\"\"Set learning rate.\"\"\"\n",
    "    lr_each_step = []\n",
    "    for i in range(global_step):\n",
    "        if steps:\n",
    "            lr_each_step.append(learning_rate * (decay_rate ** (i // decay_step)))\n",
    "        else:\n",
    "            lr_each_step.append(learning_rate * (decay_rate ** (i / decay_step)))\n",
    "    lr_each_step = np.array(lr_each_step).astype(np.float32)\n",
    "    lr_each_step = lr_each_step[start_step:]\n",
    "    return lr_each_step\n",
    "\n",
    "\n",
    "def init_net_param(network, init_value='ones'):\n",
    "    \"\"\"Init the parameters in network.\"\"\"\n",
    "    params = network.trainable_params()\n",
    "    for p in params:\n",
    "        if isinstance(p.data, Tensor) and 'beta' not in p.name and 'gamma' not in p.name and 'bias' not in p.name:\n",
    "            p.set_data(initializer(init_value, p.data.shape, p.data.dtype))\n",
    "\n",
    "\n",
    "def main(args_opt):\n",
    "    #设置运行环境，参数mode设置为默认的GRAPH_MODE模式，算力为使用昇腾算力\n",
    "\n",
    "    \n",
    "    if args_opt.distribute:\n",
    "        device_num = args_opt.device_num\n",
    "        context.reset_auto_parallel_context()\n",
    "        context.set_auto_parallel_context(parallel_mode=ParallelMode.DATA_PARALLEL, gradients_mean=True,\n",
    "                                          device_num=device_num)\n",
    "        init()\n",
    "        rank = args_opt.device_id % device_num\n",
    "    else:\n",
    "        rank = 0\n",
    "        device_num = 1\n",
    "\n",
    "    loss_scale = float(args_opt.loss_scale)\n",
    "    \n",
    "    # When create MindDataset, using the fitst mindrecord file, such as yolo.mindrecord0.\n",
    "    dataset = create_yolo_dataset(args_opt.mindrecord_file,\n",
    "                                  batch_size=args_opt.batch_size, device_num=device_num, rank=rank)\n",
    "    dataset_size = dataset.get_dataset_size()\n",
    "    print('The step size: ', dataset_size)\n",
    "    print(\"Create dataset done!\")\n",
    "\n",
    "    net = yolov3_resnet18(ConfigYOLOV3ResNet18())\n",
    "    net = YoloWithLossCell(net, ConfigYOLOV3ResNet18())\n",
    "    init_net_param(net, \"XavierUniform\")\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt_config = CheckpointConfig(save_checkpoint_steps=dataset_size * args_opt.save_checkpoint_epochs,\n",
    "                                  keep_checkpoint_max=args_opt.keep_checkpoint_max)\n",
    "    ckpoint_cb = ModelCheckpoint(prefix=\"yolov3\", directory=cfg.ckpt_dir, config=ckpt_config)\n",
    "\n",
    "    if args_opt.pre_trained:\n",
    "        if args_opt.pre_trained_epoch_size <= 0:\n",
    "            raise KeyError(\"pre_trained_epoch_size must be greater than 0.\")\n",
    "        param_dict = load_checkpoint(args_opt.pre_trained)\n",
    "        load_param_into_net(net, param_dict)\n",
    "    total_epoch_size = 60\n",
    "    if args_opt.distribute:\n",
    "        total_epoch_size = 160\n",
    "    lr = Tensor(get_lr(learning_rate=args_opt.lr, start_step=args_opt.pre_trained_epoch_size * dataset_size,\n",
    "                       global_step=total_epoch_size * dataset_size,\n",
    "                       decay_step=1000, decay_rate=0.95, steps=True))\n",
    "    # 尝试使用其他优化器，如Momentum，SGD等；\n",
    "    \n",
    "    \n",
    "    opt = nn.Adam(filter(lambda x: x.requires_grad, net.get_parameters()), lr, loss_scale=loss_scale)\n",
    "    net = TrainingWrapper(net, opt, loss_scale)\n",
    "    \n",
    "    callback = [LossMonitor(10*dataset_size), ckpoint_cb]\n",
    "    model = Model(net)\n",
    "    dataset_sink_mode = cfg.dataset_sink_mode\n",
    "    print(\"Start train YOLOv3, the first epoch will be slower because of the graph compilation.\")\n",
    "    model.train(args_opt.epoch_size, dataset, callbacks=callback, dataset_sink_mode=dataset_sink_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start create dataset!\n",
      "Create Mindrecord.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(35242:140666958619264,MainProcess):2023-10-29-11:27:23.715.757 [mindspore/dataset/core/validator_helpers.py:744] 'Decode' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Decode' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(35242:140666958619264,MainProcess):2023-10-29-11:27:23.716.526 [mindspore/dataset/core/validator_helpers.py:744] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(35242:140666958619264,MainProcess):2023-10-29-11:27:23.738.372 [mindspore/common/_decorator.py:40] 'TensorAdd' is deprecated from version 1.1 and will be removed in a future version, use 'Add' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Mindrecord Done, at ./data/mindrecord/train\n",
      "The step size:  15\n",
      "Create dataset done!\n",
      "Start train YOLOv3, the first epoch will be slower because of the graph compilation.\n",
      "epoch: 10 step: 15, loss is 273.80487060546875\n",
      "epoch: 20 step: 15, loss is 148.9776611328125\n",
      "epoch: 30 step: 15, loss is 103.55604553222656\n",
      "epoch: 40 step: 15, loss is 88.15841674804688\n",
      "epoch: 50 step: 15, loss is 86.1398696899414\n",
      "epoch: 60 step: 15, loss is 74.63165283203125\n"
     ]
    }
   ],
   "source": [
    "# ------------yolov3 train -----------------------------\n",
    "cfg = edict({\n",
    "    \"distribute\": False,\n",
    "#     \"device_id\": 0,\n",
    "#     \"device_num\": 1,\n",
    "    \"dataset_sink_mode\": True,\n",
    "\n",
    "    \"lr\": 0.001,\n",
    "    \"epoch_size\": 60,\n",
    "    \"batch_size\": 32,\n",
    "    \"loss_scale\" : 1024,\n",
    "\n",
    "    \"pre_trained\": None,\n",
    "    \"pre_trained_epoch_size\":0,\n",
    "\n",
    "    \"ckpt_dir\": \"./ckpt\",\n",
    "    \"save_checkpoint_epochs\" :1,\n",
    "    'keep_checkpoint_max': 1,\n",
    "}) \n",
    "if os.path.exists(cfg.ckpt_dir):\n",
    "    shutil.rmtree(cfg.ckpt_dir)\n",
    "data_path = './data' \n",
    "\n",
    "mindrecord_dir_train = os.path.join(data_path,'mindrecord/train')\n",
    "\n",
    "print(\"Start create dataset!\")\n",
    "# It will generate mindrecord file in args_opt.mindrecord_dir,and the file name is yolo.mindrecord.\n",
    "prefix = \"yolo.mindrecord\"\n",
    "cfg.mindrecord_file = os.path.join(mindrecord_dir_train, prefix)\n",
    "if os.path.exists(mindrecord_dir_train):\n",
    "    shutil.rmtree(mindrecord_dir_train)\n",
    "\n",
    "image_dir = os.path.join(data_path, \"train\")\n",
    "if os.path.exists(mindrecord_dir_train) and os.listdir(mindrecord_dir_train):\n",
    "    print('The mindrecord file had exists!')\n",
    "else:\n",
    "    image_dir = os.path.join(data_path, \"train\")\n",
    "    if not os.path.exists(mindrecord_dir_train):\n",
    "        os.makedirs(mindrecord_dir_train)\n",
    "    print(\"Create Mindrecord.\")\n",
    "    data_to_mindrecord_byte_image(image_dir, mindrecord_dir_train, prefix, 1)\n",
    "    print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir_train))\n",
    "    # if you need use mindrecord file next time, you can save them to yours obs.\n",
    "    #mox.file.copy_parallel(src_url=args_opt.mindrecord_dir_train, dst_url=os.path.join(cfg.data_url,'mindspore/train')\n",
    "\n",
    "main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from easydict import EasyDict as edict\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "import sys\n",
    "#sys.path.insert(0,'./yolov3/code/')\n",
    "sys.path.insert(0,'./src/yolov3/yolov3_resnet18/') # yours code path\n",
    "# import moxing as mox\n",
    "from mindspore import context, Tensor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "from src.yolov3 import yolov3_resnet18, YoloWithEval\n",
    "from src.dataset import create_yolo_dataset, data_to_mindrecord_byte_image\n",
    "from src.config import ConfigYOLOV3ResNet18\n",
    "from src.utils import metrics\n",
    "def apply_nms(all_boxes, all_scores, thres, max_boxes):\n",
    "    \"\"\"Apply NMS to bboxes.\"\"\"\n",
    "    x1 = all_boxes[:, 0]\n",
    "    y1 = all_boxes[:, 1]\n",
    "    x2 = all_boxes[:, 2]\n",
    "    y2 = all_boxes[:, 3]\n",
    "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    order = all_scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if len(keep) >= max_boxes:\n",
    "            break\n",
    "    xx1 = np.maximum(x1[i], x1[order[1:]])\n",
    "    yy1 = np.maximum(y1[i], y1[order[1:]])\n",
    "    xx2 = np.minimum(x2[i], x2[order[1:]])\n",
    "    yy2 = np.minimum(y2[i], y2[order[1:]])\n",
    "    w = np.maximum(0.0, xx2 - xx1 + 1)\n",
    "    h = np.maximum(0.0, yy2 - yy1 + 1)\n",
    "    inter = w * h\n",
    "    ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
    "    inds = np.where(ovr <= thres)[0]\n",
    "    order = order[inds + 1]\n",
    "    return keep\n",
    "\n",
    "def tobox(boxes, box_scores):\n",
    "    \"\"\"Calculate precision and recall of predicted bboxes.\"\"\"\n",
    "    config = ConfigYOLOV3ResNet18()\n",
    "    num_classes = config.num_classes\n",
    "    mask = box_scores >= config.obj_threshold\n",
    "    boxes_ = []\n",
    "    scores_ = []\n",
    "    classes_ = []\n",
    "    max_boxes = config.nms_max_num\n",
    "    for c in range(num_classes):\n",
    "        class_boxes = np.reshape(boxes, [-1, 4])[np.reshape(mask[:, c], [-1])]\n",
    "        class_box_scores = np.reshape(box_scores[:, c], [-1])[np.reshape(mask[:, c], [-1])]\n",
    "        nms_index = apply_nms(class_boxes, class_box_scores, config.nms_threshold, \n",
    "        max_boxes)\n",
    "        #nms_index = apply_nms(class_boxes, class_box_scores, 0.5, max_boxes)\n",
    "        class_boxes = class_boxes[nms_index]\n",
    "        class_box_scores = class_box_scores[nms_index]\n",
    "        classes = np.ones_like(class_box_scores, 'int32') * c\n",
    "        boxes_.append(class_boxes)\n",
    "        scores_.append(class_box_scores)\n",
    "        classes_.append(classes)\n",
    "    boxes = np.concatenate(boxes_, axis=0)\n",
    "    classes = np.concatenate(classes_, axis=0)\n",
    "    scores = np.concatenate(scores_, axis=0)\n",
    "    return boxes, classes, scores\n",
    "\n",
    "def yolo_eval(cfg):\n",
    "    \"\"\"Yolov3 evaluation.\"\"\"\n",
    "    ds = create_yolo_dataset(cfg.mindrecord_file, batch_size=1, is_training=False)\n",
    "    config = ConfigYOLOV3ResNet18()\n",
    "    net = yolov3_resnet18(config)\n",
    "    eval_net = YoloWithEval(net, config)\n",
    "    print(\"Load Checkpoint!\")\n",
    "    param_dict = load_checkpoint(cfg.ckpt_path)\n",
    "    load_param_into_net(net, param_dict)\n",
    "    eval_net.set_train(False)\n",
    "    i = 1.\n",
    "    total = ds.get_dataset_size()\n",
    "    start = time.time()\n",
    "    pred_data = []\n",
    "    print(\"\\n========================================\\n\")\n",
    "    print(\"total images num: \", total)\n",
    "    print(\"Processing, please wait a moment.\")\n",
    "    \n",
    "    num_class={0:'person', 1: 'face', 2:'mask'}\n",
    "    for data in ds.create_dict_iterator(output_numpy=True):\n",
    "        img_np = data['image']\n",
    "        image_shape = data['image_shape']\n",
    "        #print(image_shape)\n",
    "        annotation = data['annotation']\n",
    "        image_file = data['file']\n",
    "        image_file = image_file.tostring().decode('ascii')\n",
    "    \n",
    "    eval_net.set_train(False)\n",
    "    output = eval_net(Tensor(img_np), Tensor(image_shape))\n",
    "    for batch_idx in range(img_np.shape[0]):\n",
    "        boxes = output[0].asnumpy()[batch_idx]\n",
    "        box_scores = output[1].asnumpy()[batch_idx]\n",
    "        image = img_np[batch_idx,...]\n",
    "        boxes, classes, scores =tobox(boxes, box_scores)\n",
    "        #print(classes)\n",
    "        #print(scores)\n",
    "        fig = plt.figure() #相当于创建画板\n",
    "        ax = fig.add_subplot(1,1,1) #创建子图，相当于在画板中添加一个画纸，当然可创建多个画纸，\n",
    "        具体由其中参数而定\n",
    "        image_path = os.path.join(cfg.image_dir, image_file)\n",
    "        f = Image.open(image_path) \n",
    "        img_np = np.asarray(f ,dtype=np.float32) #H，W，C 格式 \n",
    "        ax.imshow(img_np.astype(np.uint8)) #当前画纸中画一个图片\n",
    "        \n",
    "        for box_index in range(boxes.shape[0]):\n",
    "            ymin=boxes[box_index][0]\n",
    "            xmin=boxes[box_index][1]\n",
    "            ymax=boxes[box_index][2]\n",
    "            xmax=boxes[box_index][3]\n",
    "            ax.add_patch(plt.Rectangle((xmin,ymin),(xmax-xmin),(ymax-ymin),fill=False,edgecolor='red', linewidth=2))\n",
    " #给方框加标注，xmin,ymin 表示 x,y 坐标，其它相当于画笔属性\n",
    "            ax.text(xmin,ymin,s = str(num_class[classes[box_index]])+str(scores[box_index]),\n",
    "                    style='italic',bbox={'facecolor': 'blue', 'alpha': 0.5, 'pad': 0})\n",
    "    plt.show()\n",
    " #print(xmin,ymin,xmax,ymax)\n",
    " #添加方框，(xmin,ymin)表示左顶点坐标，(xmax-xmin),(ymax-ymin)表示方框长宽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(35242:140666958619264,MainProcess):2023-10-29-11:48:34.406.303 [mindspore/dataset/core/validator_helpers.py:744] 'Decode' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Decode' from mindspore.dataset.vision instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mindrecord file had exists!\n",
      "Start Eval!\n",
      "Load Checkpoint!\n",
      "\n",
      "========================================\n",
      "\n",
      "total images num:  8\n",
      "Processing, please wait a moment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35242/3539336857.py:96: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  image_file = image_file.tostring().decode('ascii')\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/root/work/code/main.ipynb 单元格 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# if you need use mindrecord file next time, you can save them to yours obs.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m#mox.file.copy_parallel(src_url=args_opt.mindrecord_dir_test, dst_url=os.path.join(cfg.data_url,'mindspore/test')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStart Eval!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m yolo_eval(cfg)\n",
      "\u001b[1;32m/root/work/code/main.ipynb 单元格 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=101'>102</a>\u001b[0m box_scores \u001b[39m=\u001b[39m output[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39masnumpy()[batch_idx]\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=102'>103</a>\u001b[0m image \u001b[39m=\u001b[39m img_np[batch_idx,\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m boxes, classes, scores \u001b[39m=\u001b[39mtobox(boxes, box_scores)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m#print(classes)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39m#print(scores)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=106'>107</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure() \u001b[39m#相当于创建画板\u001b[39;00m\n",
      "\u001b[1;32m/root/work/code/main.ipynb 单元格 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m class_boxes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(boxes, [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m])[np\u001b[39m.\u001b[39mreshape(mask[:, c], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m class_box_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(box_scores[:, c], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])[np\u001b[39m.\u001b[39mreshape(mask[:, c], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m nms_index \u001b[39m=\u001b[39m apply_nms(class_boxes, class_box_scores, config\u001b[39m.\u001b[39;49mnms_threshold, \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m max_boxes)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#nms_index = apply_nms(class_boxes, class_box_scores, 0.5, max_boxes)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m class_boxes \u001b[39m=\u001b[39m class_boxes[nms_index]\n",
      "\u001b[1;32m/root/work/code/main.ipynb 单元格 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(keep) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_boxes:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m xx1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(x1[i], x1[order[\u001b[39m1\u001b[39m:]])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m yy1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(y1[i], y1[order[\u001b[39m1\u001b[39m:]])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a22485541574549227d/root/work/code/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m xx2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mminimum(x2[i], x2[order[\u001b[39m1\u001b[39m:]])\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'i' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# ---------------yolov3  test-------------------------\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n",
    "\n",
    "ckpt_path = './ckpt/'\n",
    "# if not os.path.exists(ckpt_path):\n",
    "#     mox.file.copy_parallel(src_url=args_opt.ckpt_url, dst_url=ckpt_path)\n",
    "cfg.ckpt_path = os.path.join(ckpt_path, \"yolov3-60_15.ckpt\") \n",
    "\n",
    "data_path = './data/' \n",
    "# if not os.path.exists(data_path):\n",
    "#     mox.file.copy_parallel(src_url=data_url, dst_url=data_path)\n",
    "\n",
    "mindrecord_dir_test = os.path.join(data_path,'mindrecord/test')   \n",
    "prefix = \"yolo.mindrecord\"\n",
    "cfg.mindrecord_file = os.path.join(mindrecord_dir_test, prefix)\n",
    "cfg.image_dir = os.path.join(data_path, \"test\")\n",
    "if os.path.exists(mindrecord_dir_test) and os.listdir(mindrecord_dir_test):\n",
    "    print('The mindrecord file had exists!')\n",
    "else:\n",
    "    if not os.path.isdir(mindrecord_dir_test):\n",
    "        os.makedirs(mindrecord_dir_test)\n",
    "    prefix = \"yolo.mindrecord\"\n",
    "    cfg.mindrecord_file = os.path.join(mindrecord_dir_test, prefix)\n",
    "    print(\"Create Mindrecord.\")\n",
    "    data_to_mindrecord_byte_image(cfg.image_dir, mindrecord_dir_test, prefix, 1)\n",
    "    print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir_test))\n",
    "    # if you need use mindrecord file next time, you can save them to yours obs.\n",
    "    #mox.file.copy_parallel(src_url=args_opt.mindrecord_dir_test, dst_url=os.path.join(cfg.data_url,'mindspore/test')\n",
    "print(\"Start Eval!\")\n",
    "\n",
    "yolo_eval(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
